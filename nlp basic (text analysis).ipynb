{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d9814818",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"this is the nlp session that is going on finally we are happy.We are learning online from ineuron.im from fsds batch 2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0d08706e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the nlp session that is going on finally we are happy.We are learning online from ineuron.im from fsds batch 2.0'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c43b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30b5d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "496851e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization #creates a list of sentences from paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8bb665a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencess=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c421128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is the nlp session that is going on finally we are happy.We are learning online from ineuron.im from fsds batch 2.0']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc678f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nlp',\n",
       " 'session',\n",
       " 'that',\n",
       " 'is',\n",
       " 'going',\n",
       " 'on',\n",
       " 'finally',\n",
       " 'we',\n",
       " 'are',\n",
       " 'happy.We',\n",
       " 'are',\n",
       " 'learning',\n",
       " 'online',\n",
       " 'from',\n",
       " 'ineuron.im',\n",
       " 'from',\n",
       " 'fsds',\n",
       " 'batch',\n",
       " '2.0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51875741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steming\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64f48743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e53c2be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3768/2822215824.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"happy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mto_lowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "stemmer.stem(\"happy\",to_lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87d33c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f8ebb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"happy\",to_lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d94be689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c057986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b2480ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7249028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historical'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "654a28b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happiness'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"happiness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57ac4fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is the nlp session that is going on finally we are happy.We are learning online from ineuron.im from fsds batch 2.0']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0657146",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c80a2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi is the nlp session that is go on final we are happy.w are learn onlin from ineuron.im from fsd batch 2.0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b52f0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4cde704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a20dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "742827d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58fae208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8c3c25c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'C:\\\\Users\\\\akshay\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3768/2594391243.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hindi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     19\u001b[0m         return [\n\u001b[0;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m    229\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file or directory: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No such file or directory: 'C:\\\\Users\\\\akshay\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f4d05cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chnage\n",
      "change\n",
      "chnaging\n",
      "changer\n",
      "changeable\n"
     ]
    }
   ],
   "source": [
    "for i in [\"chnage\",\"change\",\"chnaging\",\"changer\",\"changeable\"]:\n",
    "    print(lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cda1861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1=\"\"\"Ratan Naval Tata (born 28 December 1937) is an Indian businessman and former chairman of Tata Sons. He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017. He continues to head its charitable trusts.[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.[4]\n",
    "\n",
    "He is the son of Naval Tata, who was adopted by Ratanji Tata, son of Jamsetji Tata, the founder of the Tata Group. He graduated from the Cornell University College of Architecture with a bachelor's degree in architecture.[5] He joined Tata in 1961, where he worked on the shop floor of Tata Steel. He later succeeded J. R. D. Tata's as chairman of Tata Sons upon the latter's retirement in 1991. Under his tenure the Tata Group acquired Tetley, Jaguar Land Rover, and Corus, in an attempt to turn Tata from a largely India-centric group into a global business. Tata is also one of the largest philanthropists in the world, having donated around 60–65% of his income to charity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40f2c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ratan Naval Tata (born 28 December 1937) is an Indian businessman and former chairman of Tata Sons. He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017. He continues to head its charitable trusts.[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.[4]\\n\\nHe is the son of Naval Tata, who was adopted by Ratanji Tata, son of Jamsetji Tata, the founder of the Tata Group. He graduated from the Cornell University College of Architecture with a bachelor's degree in architecture.[5] He joined Tata in 1961, where he worked on the shop floor of Tata Steel. He later succeeded J. R. D. Tata's as chairman of Tata Sons upon the latter's retirement in 1991. Under his tenure the Tata Group acquired Tetley, Jaguar Land Rover, and Corus, in an attempt to turn Tata from a largely India-centric group into a global business. Tata is also one of the largest philanthropists in the world, having donated around 60–65% of his income to charity.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00b4773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1=nltk.sent_tokenize(paragraph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56dd2096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ratan Naval Tata (born 28 December 1937) is an Indian businessman and former chairman of Tata Sons.',\n",
       " 'He was also the chairman of the Tata Group from 1990 to 2012, serving also as interim chairman from October 2016 through February 2017.',\n",
       " 'He continues to head its charitable trusts.',\n",
       " '[2][3] In 2008, he received the Padma Vibhushan, the second highest civilian honour in India, after receiving the Padma Bhushan, the third highest civilian honour in 2000.',\n",
       " '[4]\\n\\nHe is the son of Naval Tata, who was adopted by Ratanji Tata, son of Jamsetji Tata, the founder of the Tata Group.',\n",
       " \"He graduated from the Cornell University College of Architecture with a bachelor's degree in architecture.\",\n",
       " '[5] He joined Tata in 1961, where he worked on the shop floor of Tata Steel.',\n",
       " \"He later succeeded J. R. D. Tata's as chairman of Tata Sons upon the latter's retirement in 1991.\",\n",
       " 'Under his tenure the Tata Group acquired Tetley, Jaguar Land Rover, and Corus, in an attempt to turn Tata from a largely India-centric group into a global business.',\n",
       " 'Tata is also one of the largest philanthropists in the world, having donated around 60–65% of his income to charity.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bdd238f",
   "metadata": {},
   "outputs": [],
   "source": [
    " words=nltk.word_tokenize(paragraph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3be4703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ratan',\n",
       " 'Naval',\n",
       " 'Tata',\n",
       " '(',\n",
       " 'born',\n",
       " '28',\n",
       " 'December',\n",
       " '1937',\n",
       " ')',\n",
       " 'is',\n",
       " 'an',\n",
       " 'Indian',\n",
       " 'businessman',\n",
       " 'and',\n",
       " 'former',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'Tata',\n",
       " 'Sons',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'also',\n",
       " 'the',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Tata',\n",
       " 'Group',\n",
       " 'from',\n",
       " '1990',\n",
       " 'to',\n",
       " '2012',\n",
       " ',',\n",
       " 'serving',\n",
       " 'also',\n",
       " 'as',\n",
       " 'interim',\n",
       " 'chairman',\n",
       " 'from',\n",
       " 'October',\n",
       " '2016',\n",
       " 'through',\n",
       " 'February',\n",
       " '2017',\n",
       " '.',\n",
       " 'He',\n",
       " 'continues',\n",
       " 'to',\n",
       " 'head',\n",
       " 'its',\n",
       " 'charitable',\n",
       " 'trusts',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'In',\n",
       " '2008',\n",
       " ',',\n",
       " 'he',\n",
       " 'received',\n",
       " 'the',\n",
       " 'Padma',\n",
       " 'Vibhushan',\n",
       " ',',\n",
       " 'the',\n",
       " 'second',\n",
       " 'highest',\n",
       " 'civilian',\n",
       " 'honour',\n",
       " 'in',\n",
       " 'India',\n",
       " ',',\n",
       " 'after',\n",
       " 'receiving',\n",
       " 'the',\n",
       " 'Padma',\n",
       " 'Bhushan',\n",
       " ',',\n",
       " 'the',\n",
       " 'third',\n",
       " 'highest',\n",
       " 'civilian',\n",
       " 'honour',\n",
       " 'in',\n",
       " '2000',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'He',\n",
       " 'is',\n",
       " 'the',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Naval',\n",
       " 'Tata',\n",
       " ',',\n",
       " 'who',\n",
       " 'was',\n",
       " 'adopted',\n",
       " 'by',\n",
       " 'Ratanji',\n",
       " 'Tata',\n",
       " ',',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Jamsetji',\n",
       " 'Tata',\n",
       " ',',\n",
       " 'the',\n",
       " 'founder',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Tata',\n",
       " 'Group',\n",
       " '.',\n",
       " 'He',\n",
       " 'graduated',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Cornell',\n",
       " 'University',\n",
       " 'College',\n",
       " 'of',\n",
       " 'Architecture',\n",
       " 'with',\n",
       " 'a',\n",
       " 'bachelor',\n",
       " \"'s\",\n",
       " 'degree',\n",
       " 'in',\n",
       " 'architecture',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'He',\n",
       " 'joined',\n",
       " 'Tata',\n",
       " 'in',\n",
       " '1961',\n",
       " ',',\n",
       " 'where',\n",
       " 'he',\n",
       " 'worked',\n",
       " 'on',\n",
       " 'the',\n",
       " 'shop',\n",
       " 'floor',\n",
       " 'of',\n",
       " 'Tata',\n",
       " 'Steel',\n",
       " '.',\n",
       " 'He',\n",
       " 'later',\n",
       " 'succeeded',\n",
       " 'J.',\n",
       " 'R.',\n",
       " 'D.',\n",
       " 'Tata',\n",
       " \"'s\",\n",
       " 'as',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'Tata',\n",
       " 'Sons',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'latter',\n",
       " \"'s\",\n",
       " 'retirement',\n",
       " 'in',\n",
       " '1991',\n",
       " '.',\n",
       " 'Under',\n",
       " 'his',\n",
       " 'tenure',\n",
       " 'the',\n",
       " 'Tata',\n",
       " 'Group',\n",
       " 'acquired',\n",
       " 'Tetley',\n",
       " ',',\n",
       " 'Jaguar',\n",
       " 'Land',\n",
       " 'Rover',\n",
       " ',',\n",
       " 'and',\n",
       " 'Corus',\n",
       " ',',\n",
       " 'in',\n",
       " 'an',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'Tata',\n",
       " 'from',\n",
       " 'a',\n",
       " 'largely',\n",
       " 'India-centric',\n",
       " 'group',\n",
       " 'into',\n",
       " 'a',\n",
       " 'global',\n",
       " 'business',\n",
       " '.',\n",
       " 'Tata',\n",
       " 'is',\n",
       " 'also',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'largest',\n",
       " 'philanthropists',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'having',\n",
       " 'donated',\n",
       " 'around',\n",
       " '60–65',\n",
       " '%',\n",
       " 'of',\n",
       " 'his',\n",
       " 'income',\n",
       " 'to',\n",
       " 'charity',\n",
       " '.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9735922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words if not word in stopwords]\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de0cae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp session go final happy.w learn onlin ineuron.im fsd batch 2.0']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "06665f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', '(', 'born', '28', 'decemb', '1937', ')', 'is', 'an', 'indian', 'businessman', 'and', 'former', 'chairman', 'of', 'tata', 'son', '.']\n",
      "['he', 'wa', 'also', 'the', 'chairman', 'of', 'the', 'tata', 'group', 'from', '1990', 'to', '2012', ',', 'serv', 'also', 'as', 'interim', 'chairman', 'from', 'octob', '2016', 'through', 'februari', '2017', '.']\n",
      "['he', 'continu', 'to', 'head', 'it', 'charit', 'trust', '.']\n",
      "['[', '2', ']', '[', '3', ']', 'in', '2008', ',', 'he', 'receiv', 'the', 'padma', 'vibhushan', ',', 'the', 'second', 'highest', 'civilian', 'honour', 'in', 'india', ',', 'after', 'receiv', 'the', 'padma', 'bhushan', ',', 'the', 'third', 'highest', 'civilian', 'honour', 'in', '2000', '.']\n",
      "['[', '4', ']', 'he', 'is', 'the', 'son', 'of', 'naval', 'tata', ',', 'who', 'wa', 'adopt', 'by', 'ratanji', 'tata', ',', 'son', 'of', 'jamsetji', 'tata', ',', 'the', 'founder', 'of', 'the', 'tata', 'group', '.']\n",
      "['he', 'graduat', 'from', 'the', 'cornel', 'univers', 'colleg', 'of', 'architectur', 'with', 'a', 'bachelor', \"'s\", 'degre', 'in', 'architectur', '.']\n",
      "['[', '5', ']', 'he', 'join', 'tata', 'in', '1961', ',', 'where', 'he', 'work', 'on', 'the', 'shop', 'floor', 'of', 'tata', 'steel', '.']\n",
      "['he', 'later', 'succeed', 'j.', 'r.', 'd.', 'tata', \"'s\", 'as', 'chairman', 'of', 'tata', 'son', 'upon', 'the', 'latter', \"'s\", 'retir', 'in', '1991', '.']\n",
      "['under', 'hi', 'tenur', 'the', 'tata', 'group', 'acquir', 'tetley', ',', 'jaguar', 'land', 'rover', ',', 'and', 'coru', ',', 'in', 'an', 'attempt', 'to', 'turn', 'tata', 'from', 'a', 'larg', 'india-centr', 'group', 'into', 'a', 'global', 'busi', '.']\n",
      "['tata', 'is', 'also', 'one', 'of', 'the', 'largest', 'philanthropist', 'in', 'the', 'world', ',', 'have', 'donat', 'around', '60–65', '%', 'of', 'hi', 'incom', 'to', 'chariti', '.']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences1)):\n",
    "    words=nltk.word_tokenize(sentences1[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3167b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata ( born 28 decemb 1937 ) is an indian businessman and former chairman of tata son .',\n",
       " 'he wa also the chairman of the tata group from 1990 to 2012 , serv also as interim chairman from octob 2016 through februari 2017 .',\n",
       " 'he continu to head it charit trust .',\n",
       " '[ 2 ] [ 3 ] in 2008 , he receiv the padma vibhushan , the second highest civilian honour in india , after receiv the padma bhushan , the third highest civilian honour in 2000 .',\n",
       " '[ 4 ] he is the son of naval tata , who wa adopt by ratanji tata , son of jamsetji tata , the founder of the tata group .',\n",
       " \"he graduat from the cornel univers colleg of architectur with a bachelor 's degre in architectur .\",\n",
       " '[ 5 ] he join tata in 1961 , where he work on the shop floor of tata steel .',\n",
       " \"he later succeed j. r. d. tata 's as chairman of tata son upon the latter 's retir in 1991 .\",\n",
       " 'under hi tenur the tata group acquir tetley , jaguar land rover , and coru , in an attempt to turn tata from a larg india-centr group into a global busi .',\n",
       " 'tata is also one of the largest philanthropist in the world , have donat around 60–65 % of hi incom to chariti .']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "598e466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', '(', 'born', '28', 'decemb', '1937', ')', 'indian', 'businessman', 'former', 'chairman', 'tata', 'son', '.']\n",
      "['also', 'chairman', 'tata', 'group', '1990', '2012', ',', 'serv', 'also', 'interim', 'chairman', 'octob', '2016', 'februari', '2017', '.']\n",
      "['continu', 'head', 'charit', 'trust', '.']\n",
      "['[', '2', ']', '[', '3', ']', '2008', ',', 'receiv', 'padma', 'vibhushan', ',', 'second', 'highest', 'civilian', 'honour', 'india', ',', 'receiv', 'padma', 'bhushan', ',', 'third', 'highest', 'civilian', 'honour', '2000', '.']\n",
      "['[', '4', ']', 'son', 'naval', 'tata', ',', 'adopt', 'ratanji', 'tata', ',', 'son', 'jamsetji', 'tata', ',', 'founder', 'tata', 'group', '.']\n",
      "['graduat', 'cornel', 'univers', 'colleg', 'architectur', 'bachelor', \"'s\", 'degre', 'architectur', '.']\n",
      "['[', '5', ']', 'join', 'tata', '1961', ',', 'work', 'shop', 'floor', 'tata', 'steel', '.']\n",
      "['later', 'succeed', 'j.', 'r.', 'd.', 'tata', \"'s\", 'chairman', 'tata', 'son', 'upon', 'latter', \"'s\", 'retir', '1991', '.']\n",
      "['tenur', 'tata', 'group', 'acquir', 'tetley', ',', 'jaguar', 'land', 'rover', ',', 'coru', ',', 'attempt', 'turn', 'tata', 'larg', 'india-centr', 'group', 'global', 'busi', '.']\n",
      "['tata', 'also', 'one', 'largest', 'philanthropist', 'world', ',', 'donat', 'around', '60–65', '%', 'incom', 'chariti', '.']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences1)): \n",
    "    words=nltk.word_tokenize(sentences1[i].lower())\n",
    "    words=[stemmer.stem(word) for word in words if not word in stopwords]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53816c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c99acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1=\"\"\"Avul Pakir Jainulabdeen Abdul Kalam (/ˈɑːbdəl kəˈlɑːm/ (listen); 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the 11th President of India from 2002 to 2007. He was born and raised in Rameswaram, Tamil Nadu and studied physics and aerospace engineering. He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts.[1] He thus came to be known as the Missile Man of India for his work on the development of ballistic missile and launch vehicle technology.[2][3][4] He also played a pivotal organisational, technical, and political role in India's Pokhran-II nuclear tests in 1998, the first since the original nuclear test by India in 1974.[5]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de52eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Avul Pakir Jainulabdeen Abdul Kalam (/ˈɑːbdəl kəˈlɑːm/ (listen); 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the 11th President of India from 2002 to 2007. He was born and raised in Rameswaram, Tamil Nadu and studied physics and aerospace engineering. He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts.[1] He thus came to be known as the Missile Man of India for his work on the development of ballistic missile and launch vehicle technology.[2][3][4] He also played a pivotal organisational, technical, and political role in India's Pokhran-II nuclear tests in 1998, the first since the original nuclear test by India in 1974.[5]\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0be40447",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2=nltk.sent_tokenize(paragraph1) #separates sentences of paragrpah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fa3f8cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avul Pakir Jainulabdeen Abdul Kalam (/ˈɑːbdəl kəˈlɑːm/ (listen); 15 October 1931 – 27 July 2015) was an Indian aerospace scientist and statesman who served as the 11th President of India from 2002 to 2007.',\n",
       " 'He was born and raised in Rameswaram, Tamil Nadu and studied physics and aerospace engineering.',\n",
       " \"He spent the next four decades as a scientist and science administrator, mainly at the Defence Research and Development Organisation (DRDO) and Indian Space Research Organisation (ISRO) and was intimately involved in India's civilian space programme and military missile development efforts.\",\n",
       " '[1] He thus came to be known as the Missile Man of India for his work on the development of ballistic missile and launch vehicle technology.',\n",
       " \"[2][3][4] He also played a pivotal organisational, technical, and political role in India's Pokhran-II nuclear tests in 1998, the first since the original nuclear test by India in 1974.\",\n",
       " '[5]']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fca73a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', '(', '/ˈɑːbdəl', 'kəˈlɑːm/', '(', 'listen', ')', ';', '15', 'octob', '1931', '–', '27', 'juli', '2015', ')', 'wa', 'an', 'indian', 'aerospac', 'scientist', 'and', 'statesman', 'who', 'serv', 'as', 'the', '11th', 'presid', 'of', 'india', 'from', '2002', 'to', '2007', '.']\n",
      "['he', 'wa', 'born', 'and', 'rais', 'in', 'rameswaram', ',', 'tamil', 'nadu', 'and', 'studi', 'physic', 'and', 'aerospac', 'engin', '.']\n",
      "['he', 'spent', 'the', 'next', 'four', 'decad', 'as', 'a', 'scientist', 'and', 'scienc', 'administr', ',', 'mainli', 'at', 'the', 'defenc', 'research', 'and', 'develop', 'organis', '(', 'drdo', ')', 'and', 'indian', 'space', 'research', 'organis', '(', 'isro', ')', 'and', 'wa', 'intim', 'involv', 'in', 'india', \"'s\", 'civilian', 'space', 'programm', 'and', 'militari', 'missil', 'develop', 'effort', '.']\n",
      "['[', '1', ']', 'he', 'thu', 'came', 'to', 'be', 'known', 'as', 'the', 'missil', 'man', 'of', 'india', 'for', 'hi', 'work', 'on', 'the', 'develop', 'of', 'ballist', 'missil', 'and', 'launch', 'vehicl', 'technolog', '.']\n",
      "['[', '2', ']', '[', '3', ']', '[', '4', ']', 'he', 'also', 'play', 'a', 'pivot', 'organis', ',', 'technic', ',', 'and', 'polit', 'role', 'in', 'india', \"'s\", 'pokhran-ii', 'nuclear', 'test', 'in', '1998', ',', 'the', 'first', 'sinc', 'the', 'origin', 'nuclear', 'test', 'by', 'india', 'in', '1974', '.']\n",
      "['[', '5', ']']\n"
     ]
    }
   ],
   "source": [
    "corpus1=[]\n",
    "for i in range(len(sentences2)):\n",
    "    words=nltk.word_tokenize(sentences2[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a909c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', '(', '/ˈɑːbdəl', 'kəˈlɑːm/', '(', 'listen', ')', ';', '15', 'octob', '1931', '–', '27', 'juli', '2015', ')', 'indian', 'aerospac', 'scientist', 'statesman', 'serv', '11th', 'presid', 'india', '2002', '2007', '.']\n",
      "['he', 'born', 'rais', 'rameswaram', ',', 'tamil', 'nadu', 'studi', 'physic', 'aerospac', 'engin', '.']\n",
      "['he', 'spent', 'next', 'four', 'decad', 'scientist', 'scienc', 'administr', ',', 'mainli', 'defenc', 'research', 'develop', 'organis', '(', 'drdo', ')', 'indian', 'space', 'research', 'organis', '(', 'isro', ')', 'intim', 'involv', 'india', \"'s\", 'civilian', 'space', 'programm', 'militari', 'missil', 'develop', 'effort', '.']\n",
      "['[', '1', ']', 'he', 'thu', 'came', 'known', 'missil', 'man', 'india', 'work', 'develop', 'ballist', 'missil', 'launch', 'vehicl', 'technolog', '.']\n",
      "['[', '2', ']', '[', '3', ']', '[', '4', ']', 'he', 'also', 'play', 'pivot', 'organis', ',', 'technic', ',', 'polit', 'role', 'india', \"'s\", 'pokhran-ii', 'nuclear', 'test', '1998', ',', 'first', 'sinc', 'origin', 'nuclear', 'test', 'india', '1974', '.']\n",
      "['[', '5', ']']\n"
     ]
    }
   ],
   "source": [
    "corpus1=[]\n",
    "for i in range(len(sentences2)):\n",
    "    words=nltk.word_tokenize(sentences2[i])\n",
    "    words=[stemmer.stem(word) for word in words if not word in stopwords]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a4a2fca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d1997b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avul', 'pakir', 'jainulabdeen', 'abdul', 'kalam', 'bd', 'l', 'k', 'l', 'listen', '15', 'octob', '1931', '27', 'juli', '2015', 'indian', 'aerospac', 'scientist', 'statesman', 'serv', '11th', 'presid', 'india', '2002', '2007']\n",
      "['born', 'rais', 'rameswaram', 'tamil', 'nadu', 'studi', 'physic', 'aerospac', 'engin']\n",
      "['spent', 'next', 'four', 'decad', 'scientist', 'scienc', 'administr', 'mainli', 'defenc', 'research', 'develop', 'organis', 'drdo', 'indian', 'space', 'research', 'organis', 'isro', 'intim', 'involv', 'india', 'civilian', 'space', 'programm', 'militari', 'missil', 'develop', 'effort']\n",
      "['[1]', 'thu', 'came', 'known', 'missil', 'man', 'india', 'work', 'develop', 'ballist', 'missil', 'launch', 'vehicl', 'technolog']\n",
      "['[2][3][4]', 'also', 'play', 'pivot', 'organis', 'technic', 'polit', 'role', 'india', 'pokhran', 'ii', 'nuclear', 'test', '1998', 'first', 'sinc', 'origin', 'nuclear', 'test', 'india', '1974']\n",
      "['[5]']\n"
     ]
    }
   ],
   "source": [
    "import re #regular expression\n",
    "\n",
    "corpus4=[]\n",
    "for i in range(len(sentences2)):\n",
    "    text=re.sub('[^a-zA-z0-9]',' ',sentences2[i])\n",
    "    #^a-zA-z0-9 substitute with space\n",
    "    text=text.lower()\n",
    "    words=text.split()\n",
    "    words=[stemmer.stem(word) for word in words if not word in stopwords]\n",
    "    print(words)\n",
    "    corpus4.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "62bc65c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avul pakir jainulabdeen abdul kalam bd l k l listen 15 octob 1931 27 juli 2015 indian aerospac scientist statesman serv 11th presid india 2002 2007',\n",
       " 'born rais rameswaram tamil nadu studi physic aerospac engin',\n",
       " 'spent next four decad scientist scienc administr mainli defenc research develop organis drdo indian space research organis isro intim involv india civilian space programm militari missil develop effort',\n",
       " '[1] thu came known missil man india work develop ballist missil launch vehicl technolog',\n",
       " '[2][3][4] also play pivot organis technic polit role india pokhran ii nuclear test 1998 first sinc origin nuclear test india 1974',\n",
       " '[5]']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a456a38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d249cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b407ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "519543d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        2, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applied bag of word (bow)\n",
    "#vocabulary or sparse matrix \n",
    "cv.fit_transform(corpus4).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1898642f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 163)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6 sentences/docs and 163 vector/words in matrix or bag of words\n",
    "cv.fit_transform(corpus4).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8932f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avul': 25,\n",
       " 'pakir': 106,\n",
       " 'jainulabdeen': 70,\n",
       " 'abdul': 16,\n",
       " 'kalam': 74,\n",
       " 'bd': 29,\n",
       " 'listen': 80,\n",
       " '15': 2,\n",
       " 'octob': 98,\n",
       " '1931': 4,\n",
       " '27': 14,\n",
       " 'juli': 72,\n",
       " '2015': 12,\n",
       " 'indian': 61,\n",
       " 'aerospac': 20,\n",
       " 'scientist': 133,\n",
       " 'statesman': 145,\n",
       " 'serv': 136,\n",
       " '11th': 0,\n",
       " 'presid': 118,\n",
       " 'india': 55,\n",
       " '2002': 9,\n",
       " '2007': 11,\n",
       " 'avul pakir': 26,\n",
       " 'pakir jainulabdeen': 107,\n",
       " 'jainulabdeen abdul': 71,\n",
       " 'abdul kalam': 17,\n",
       " 'kalam bd': 75,\n",
       " 'bd listen': 30,\n",
       " 'listen 15': 81,\n",
       " '15 octob': 3,\n",
       " 'octob 1931': 99,\n",
       " '1931 27': 5,\n",
       " '27 juli': 15,\n",
       " 'juli 2015': 73,\n",
       " '2015 indian': 13,\n",
       " 'indian aerospac': 62,\n",
       " 'aerospac scientist': 22,\n",
       " 'scientist statesman': 135,\n",
       " 'statesman serv': 146,\n",
       " 'serv 11th': 137,\n",
       " '11th presid': 1,\n",
       " 'presid india': 119,\n",
       " 'india 2002': 57,\n",
       " '2002 2007': 10,\n",
       " 'born': 31,\n",
       " 'rais': 122,\n",
       " 'rameswaram': 124,\n",
       " 'tamil': 149,\n",
       " 'nadu': 92,\n",
       " 'studi': 147,\n",
       " 'physic': 108,\n",
       " 'engin': 48,\n",
       " 'born rais': 32,\n",
       " 'rais rameswaram': 123,\n",
       " 'rameswaram tamil': 125,\n",
       " 'tamil nadu': 150,\n",
       " 'nadu studi': 93,\n",
       " 'studi physic': 148,\n",
       " 'physic aerospac': 109,\n",
       " 'aerospac engin': 21,\n",
       " 'spent': 143,\n",
       " 'next': 94,\n",
       " 'four': 51,\n",
       " 'decad': 37,\n",
       " 'scienc': 131,\n",
       " 'administr': 18,\n",
       " 'mainli': 82,\n",
       " 'defenc': 39,\n",
       " 'research': 126,\n",
       " 'develop': 41,\n",
       " 'organis': 100,\n",
       " 'drdo': 45,\n",
       " 'space': 140,\n",
       " 'isro': 68,\n",
       " 'intim': 64,\n",
       " 'involv': 66,\n",
       " 'civilian': 35,\n",
       " 'programm': 120,\n",
       " 'militari': 86,\n",
       " 'missil': 88,\n",
       " 'effort': 47,\n",
       " 'spent next': 144,\n",
       " 'next four': 95,\n",
       " 'four decad': 52,\n",
       " 'decad scientist': 38,\n",
       " 'scientist scienc': 134,\n",
       " 'scienc administr': 132,\n",
       " 'administr mainli': 19,\n",
       " 'mainli defenc': 83,\n",
       " 'defenc research': 40,\n",
       " 'research develop': 127,\n",
       " 'develop organis': 44,\n",
       " 'organis drdo': 101,\n",
       " 'drdo indian': 46,\n",
       " 'indian space': 63,\n",
       " 'space research': 142,\n",
       " 'research organis': 128,\n",
       " 'organis isro': 102,\n",
       " 'isro intim': 69,\n",
       " 'intim involv': 65,\n",
       " 'involv india': 67,\n",
       " 'india civilian': 58,\n",
       " 'civilian space': 36,\n",
       " 'space programm': 141,\n",
       " 'programm militari': 121,\n",
       " 'militari missil': 87,\n",
       " 'missil develop': 89,\n",
       " 'develop effort': 43,\n",
       " 'thu': 157,\n",
       " 'came': 33,\n",
       " 'known': 76,\n",
       " 'man': 84,\n",
       " 'work': 161,\n",
       " 'ballist': 27,\n",
       " 'launch': 78,\n",
       " 'vehicl': 159,\n",
       " 'technolog': 153,\n",
       " 'thu came': 158,\n",
       " 'came known': 34,\n",
       " 'known missil': 77,\n",
       " 'missil man': 91,\n",
       " 'man india': 85,\n",
       " 'india work': 60,\n",
       " 'work develop': 162,\n",
       " 'develop ballist': 42,\n",
       " 'ballist missil': 28,\n",
       " 'missil launch': 90,\n",
       " 'launch vehicl': 79,\n",
       " 'vehicl technolog': 160,\n",
       " 'also': 23,\n",
       " 'play': 112,\n",
       " 'pivot': 110,\n",
       " 'technic': 151,\n",
       " 'polit': 116,\n",
       " 'role': 129,\n",
       " 'pokhran': 114,\n",
       " 'ii': 53,\n",
       " 'nuclear': 96,\n",
       " 'test': 154,\n",
       " '1998': 7,\n",
       " 'first': 49,\n",
       " 'sinc': 138,\n",
       " 'origin': 104,\n",
       " '1974': 6,\n",
       " 'also play': 24,\n",
       " 'play pivot': 113,\n",
       " 'pivot organis': 111,\n",
       " 'organis technic': 103,\n",
       " 'technic polit': 152,\n",
       " 'polit role': 117,\n",
       " 'role india': 130,\n",
       " 'india pokhran': 59,\n",
       " 'pokhran ii': 115,\n",
       " 'ii nuclear': 54,\n",
       " 'nuclear test': 97,\n",
       " 'test 1998': 155,\n",
       " '1998 first': 8,\n",
       " 'first sinc': 50,\n",
       " 'sinc origin': 139,\n",
       " 'origin nuclear': 105,\n",
       " 'test india': 156,\n",
       " 'india 1974': 56}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_ # vocabulary gives index words in sparse matrix not paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b630f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6dfda881",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dfd7faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.27210889, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "159d0c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratan': 129,\n",
       " 'naval': 108,\n",
       " 'tata': 150,\n",
       " 'born': 40,\n",
       " '28': 18,\n",
       " 'decemb': 55,\n",
       " '1937': 3,\n",
       " 'indian': 83,\n",
       " 'businessman': 42,\n",
       " 'former': 67,\n",
       " 'chairman': 46,\n",
       " 'son': 142,\n",
       " 'also': 26,\n",
       " 'group': 73,\n",
       " '1990': 6,\n",
       " '2012': 13,\n",
       " 'serv': 139,\n",
       " 'interim': 84,\n",
       " 'octob': 111,\n",
       " '2016': 15,\n",
       " 'februari': 63,\n",
       " '2017': 16,\n",
       " 'continu': 51,\n",
       " 'head': 75,\n",
       " 'charit': 47,\n",
       " 'trust': 160,\n",
       " '2008': 12,\n",
       " 'receiv': 131,\n",
       " 'padma': 117,\n",
       " 'vibhushan': 165,\n",
       " 'second': 138,\n",
       " 'highest': 77,\n",
       " 'civilian': 49,\n",
       " 'honour': 78,\n",
       " 'india': 82,\n",
       " 'bhushan': 39,\n",
       " 'third': 157,\n",
       " '2000': 9,\n",
       " 'adopt': 24,\n",
       " 'ratanji': 130,\n",
       " 'jamsetji': 90,\n",
       " 'founder': 68,\n",
       " 'graduat': 72,\n",
       " 'cornel': 52,\n",
       " 'univers': 162,\n",
       " 'colleg': 50,\n",
       " 'architectur': 29,\n",
       " 'bachelor': 35,\n",
       " 'degre': 57,\n",
       " 'join': 91,\n",
       " '1961': 4,\n",
       " 'work': 168,\n",
       " 'shop': 140,\n",
       " 'floor': 65,\n",
       " 'steel': 146,\n",
       " 'later': 99,\n",
       " 'succeed': 148,\n",
       " 'upon': 163,\n",
       " 'latter': 100,\n",
       " 'retir': 133,\n",
       " '1991': 7,\n",
       " 'tenur': 153,\n",
       " 'acquir': 22,\n",
       " 'tetley': 155,\n",
       " 'jaguar': 88,\n",
       " 'land': 96,\n",
       " 'rover': 135,\n",
       " 'coru': 53,\n",
       " 'attempt': 33,\n",
       " 'turn': 161,\n",
       " 'larg': 97,\n",
       " 'centr': 45,\n",
       " 'global': 71,\n",
       " 'busi': 41,\n",
       " 'one': 114,\n",
       " 'largest': 98,\n",
       " 'philanthropist': 119,\n",
       " 'world': 169,\n",
       " 'donat': 59,\n",
       " 'around': 30,\n",
       " '60': 19,\n",
       " '65': 20,\n",
       " 'incom': 81,\n",
       " 'chariti': 48,\n",
       " 'avul': 34,\n",
       " 'pakir': 118,\n",
       " 'jainulabdeen': 89,\n",
       " 'abdul': 21,\n",
       " 'kalam': 93,\n",
       " 'ˈɑːbdəl': 170,\n",
       " 'kəˈlɑːm': 95,\n",
       " 'listen': 102,\n",
       " '15': 1,\n",
       " '1931': 2,\n",
       " '27': 17,\n",
       " 'juli': 92,\n",
       " '2015': 14,\n",
       " 'wa': 166,\n",
       " 'an': 27,\n",
       " 'aerospac': 25,\n",
       " 'scientist': 137,\n",
       " 'and': 28,\n",
       " 'statesman': 145,\n",
       " 'who': 167,\n",
       " 'as': 31,\n",
       " 'the': 156,\n",
       " '11th': 0,\n",
       " 'presid': 125,\n",
       " 'of': 112,\n",
       " 'from': 70,\n",
       " '2002': 10,\n",
       " 'to': 159,\n",
       " '2007': 11,\n",
       " 'he': 74,\n",
       " 'rais': 127,\n",
       " 'in': 80,\n",
       " 'rameswaram': 128,\n",
       " 'tamil': 149,\n",
       " 'nadu': 107,\n",
       " 'studi': 147,\n",
       " 'physic': 120,\n",
       " 'engin': 62,\n",
       " 'spent': 144,\n",
       " 'next': 109,\n",
       " 'four': 69,\n",
       " 'decad': 54,\n",
       " 'scienc': 136,\n",
       " 'administr': 23,\n",
       " 'mainli': 103,\n",
       " 'at': 32,\n",
       " 'defenc': 56,\n",
       " 'research': 132,\n",
       " 'develop': 58,\n",
       " 'organis': 115,\n",
       " 'drdo': 60,\n",
       " 'space': 143,\n",
       " 'isro': 87,\n",
       " 'intim': 85,\n",
       " 'involv': 86,\n",
       " 'programm': 126,\n",
       " 'militari': 105,\n",
       " 'missil': 106,\n",
       " 'effort': 61,\n",
       " 'thu': 158,\n",
       " 'came': 44,\n",
       " 'be': 38,\n",
       " 'known': 94,\n",
       " 'man': 104,\n",
       " 'for': 66,\n",
       " 'hi': 76,\n",
       " 'on': 113,\n",
       " 'ballist': 36,\n",
       " 'launch': 101,\n",
       " 'vehicl': 164,\n",
       " 'technolog': 152,\n",
       " 'play': 122,\n",
       " 'pivot': 121,\n",
       " 'technic': 151,\n",
       " 'polit': 124,\n",
       " 'role': 134,\n",
       " 'pokhran': 123,\n",
       " 'ii': 79,\n",
       " 'nuclear': 110,\n",
       " 'test': 154,\n",
       " '1998': 8,\n",
       " 'first': 64,\n",
       " 'sinc': 141,\n",
       " 'origin': 116,\n",
       " 'by': 43,\n",
       " '1974': 5,\n",
       " 'bd': 37}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "89d1f196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#supoose test data\n",
    "data =['i am akshay nikam'] \n",
    "cv.transform(data).toarray()\n",
    "#out of vocabulary so all zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8010481a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing required argument 'file' (pos 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3768/1573659859.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: dump() missing required argument 'file' (pos 2)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(open('tfidf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd999b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
