{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2d98331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b749eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\akshay\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\akshay\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\akshay\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\akshay\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akshay\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\akshay\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716bd246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')#supporting library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a73aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cd0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Data science is an interdisciplinary academic field [1] that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.[2]\n",
    "\n",
    "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc518f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2]\\n\\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)[1] #[1]represents line number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f30e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'academic',\n",
       " 'field',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " ',',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'processes',\n",
       " ',',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'or',\n",
       " 'extrapolate',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'insights',\n",
       " 'from',\n",
       " 'noisy',\n",
       " ',',\n",
       " 'structured',\n",
       " ',',\n",
       " 'and',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " '.[',\n",
       " '2',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'also',\n",
       " 'integrates',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'application',\n",
       " 'domain',\n",
       " '(',\n",
       " 'e',\n",
       " '.',\n",
       " 'g',\n",
       " '.,',\n",
       " 'natural',\n",
       " 'sciences',\n",
       " ',',\n",
       " 'information',\n",
       " 'technology',\n",
       " ',',\n",
       " 'and',\n",
       " 'medicine',\n",
       " ').[',\n",
       " '3',\n",
       " ']',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'multifaceted',\n",
       " 'and',\n",
       " 'can',\n",
       " 'be',\n",
       " 'described',\n",
       " 'as',\n",
       " 'a',\n",
       " 'science',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'paradigm',\n",
       " ',',\n",
       " 'a',\n",
       " 'research',\n",
       " 'method',\n",
       " ',',\n",
       " 'a',\n",
       " 'discipline',\n",
       " ',',\n",
       " 'a',\n",
       " 'workflow',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'profession',\n",
       " '.[',\n",
       " '4',\n",
       " ']']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.wordpunct_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f906e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=\"we are tring to test nltk lib,in ineuron class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c958e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "709422c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('tring', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('test', 'VB'),\n",
       " ('nltk', 'JJ'),\n",
       " ('lib', 'NN'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('ineuron', 'NN'),\n",
       " ('class', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prp personal pronoun (hers, herself, him, himself) from pos nltk doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0575b4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caee49de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords #corpus available only for english no local languages  u can create \n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53fcbcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22817d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "punch=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e92f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86bea0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for word in nltk.word_tokenize(text):\n",
    "    if word not in punch:\n",
    "        if word not in stopword:\n",
    "            l.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9881f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'interdisciplinary',\n",
       " 'academic',\n",
       " 'field',\n",
       " '1',\n",
       " 'uses',\n",
       " 'statistics',\n",
       " 'scientific',\n",
       " 'computing',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " 'processes',\n",
       " 'algorithms',\n",
       " 'systems',\n",
       " 'extract',\n",
       " 'extrapolate',\n",
       " 'knowledge',\n",
       " 'insights',\n",
       " 'noisy',\n",
       " 'structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " '2',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'also',\n",
       " 'integrates',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " 'underlying',\n",
       " 'application',\n",
       " 'domain',\n",
       " 'e.g.',\n",
       " 'natural',\n",
       " 'sciences',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'medicine',\n",
       " '3',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'multifaceted',\n",
       " 'described',\n",
       " 'science',\n",
       " 'research',\n",
       " 'paradigm',\n",
       " 'research',\n",
       " 'method',\n",
       " 'discipline',\n",
       " 'workflow',\n",
       " 'profession',\n",
       " '4']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l #list without stopword and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45a16aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52decd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "lancas=LancasterStemmer()\n",
    "snow=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99477043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('running') #ing remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f76b9154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hobbi'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('hobbies') #ies remove just to undesrstand exact emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "186c0f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'akshay'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('akshay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7631da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continu'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15151962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e2870ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer #converts to baseword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed7c0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akshay\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b536ea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "lemma.lemmatize('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ff8cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4c8268a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('went',pos='v') #went verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f8c0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Went'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize('Went',pos='v') #uppercase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb3a9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Amazing place great people. Your life changes the moment you enter this office. Absolutely worth visiting for events like Hackathon. The people you meet here are not good but the best of the best in IT and business industry.Went for hackathon 5.0 and the experience was really amazing. Won the 2nd prize for making an application on blockchain. Met my favourite mentors HiteshChoudhary and NaveenReddy. Really enjoyed it.They organise various hackathons covering wide range of technologies which helps lot of students and working professionals. They do a lot of community classes and have various courses related to technology. They organise a lot of meetups also with famous Youtubers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f59d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
